import os
import json
import base64
from io import BytesIO
from dotenv import load_dotenv
from typing import List
from PIL import Image
from services.utils import clean_json_string
from services.serp_service import SerpService
from schemas import DetectedObject, RippleIntent

load_dotenv()

# å°è¯•ä½¿ç”¨æ–°çš„ SDKï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°æ—§çš„
try:
    from google import genai
    from google.genai import types
    USE_NEW_SDK = True
    client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
    print("âœ… Using new Google Genai SDK")
except ImportError:
    import google.generativeai as genai
    USE_NEW_SDK = False
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    print("âš ï¸ Using old google-generativeai SDK")

# ä½¿ç”¨ä¾¿å®œå¿«é€Ÿçš„æ¨¡å‹
MODEL_NAME = 'gemini-2.0-flash'
# å›¾åƒç¼–è¾‘æ¨¡å‹ï¼ˆæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œéœ€è¦ä½¿ç”¨ä¸“é—¨çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼‰
IMAGE_EDIT_MODEL = 'gemini-2.5-flash-image'  # å®˜æ–¹æ¨èçš„å›¾åƒç¼–è¾‘æ¨¡å‹

class AIService:
    def __init__(self, enable_web_search: bool = True):
        """
        åˆå§‹åŒ– AI æœåŠ¡
        
        Args:
            enable_web_search: æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½ï¼ˆé»˜è®¤ Trueï¼‰
        """
        if USE_NEW_SDK:
            self.model_name = MODEL_NAME
            self.image_edit_model_name = IMAGE_EDIT_MODEL
        else:
            self.model = genai.GenerativeModel(MODEL_NAME)
            self.image_edit_model = genai.GenerativeModel(IMAGE_EDIT_MODEL)
        
        # åˆå§‹åŒ– SERP æœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.enable_web_search = enable_web_search
        self.serp_service = SerpService() if enable_web_search else None

    async def analyze_scene(self, image) -> List[DetectedObject]:
        """
        Step 1: å…¨å±€æ‰«æ (Pre-indexing)
        è¯†åˆ«å›¾ä¸­æ‰€æœ‰ä¸»è¦ç‰©ä½“ï¼Œè¿”å›åæ ‡ã€‚
        """
        prompt = """
        Detect all significant interactable objects in this image.
        Return a JSON list. Each entry MUST follow this format:
        {
            "label": "Short object name (e.g. Vending Machine)",
            "box_2d": [ymin, xmin, ymax, xmax] (normalized 0-1000),
        }
        Focus on: furniture, appliances, people, signs, vehicles.
        Limit to top 10 most prominent objects.
        DO NOT return segmentation masks (to save tokens).
        """
        
        try:
            if USE_NEW_SDK:
                response = client.models.generate_content(
                    model=self.model_name,
                    contents=[prompt, image],
                    config=types.GenerateContentConfig(
                        temperature=0.5,
                        thinking_config=types.ThinkingConfig(thinking_budget=0)
                    )
                )
                json_str = clean_json_string(response.text)
            else:
                response = self.model.generate_content([prompt, image])
                json_str = clean_json_string(response.text)
            data = json.loads(json_str)
            
            results = []
            width, height = image.size
            
            for i, item in enumerate(data):
                # è½¬æ¢å½’ä¸€åŒ–åæ ‡åˆ°åƒç´ åæ ‡
                y0, x0, y1, x1 = item['box_2d']
                abs_box = [
                    int(y0 / 1000 * height),
                    int(x0 / 1000 * width),
                    int(y1 / 1000 * height),
                    int(x1 / 1000 * width)
                ]
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                center = ((abs_box[1] + abs_box[3]) // 2, (abs_box[0] + abs_box[2]) // 2)

                results.append(DetectedObject(
                    id=i,
                    label=item['label'],
                    box_2d=abs_box,
                    center=center
                ))
            return results
        except Exception as e:
            print(f"Analysis Error: {e}")
            return []

    async def infer_intent(self, image, clicked_label: str, nearby_labels: List[str]) -> List[RippleIntent]:
        """
        Step 2: æ„å›¾æ¨ç† (Cached Inference with Web Search)
        æ ¹æ®ç‚¹å‡»çš„ç‰©ä½“ï¼Œç»“åˆäº’è”ç½‘èµ„æºï¼Œç”Ÿæˆ Ripple Menu é€‰é¡¹ã€‚
        """
        # æ„å»ºåŸºç¡€ prompt
        base_prompt = f"""
        User clicked on a '{clicked_label}' in the image.
        Context objects nearby: {nearby_labels}.
        """
        
        # æ£€æµ‹æ˜¯å¦ä¸ºå•†å“
        product_keywords = ['clothing', 'clothes', 'shirt', 'dress', 'jacket', 'shoe', 'bag', 
                          'accessory', 'product', 'item', 'å•†å“', 'è¡£æœ', 'é‹å­', 'åŒ…', 'é…é¥°']
        is_product = any(keyword.lower() in clicked_label.lower() for keyword in product_keywords)
        
        # å¦‚æœå¯ç”¨äº†ç½‘ç»œæœç´¢ï¼Œå…ˆæœç´¢ç›¸å…³ä¿¡æ¯
        web_context = ""
        web_results = []
        if self.enable_web_search and self.serp_service:
            print(f"ğŸŒ Searching web for: {clicked_label} {'(product)' if is_product else ''}")
            web_context, web_results = await self.serp_service.search_related_actions(
                clicked_label, 
                nearby_labels,
                is_product=is_product
            )
        
        # æ„å»ºå®Œæ•´çš„ prompt - ä»ç”¨æˆ·æ„å›¾å‡ºå‘
        prompt = f"""
        {base_prompt}
        
        {web_context if web_context else ""}
        
        **Think from the user's perspective**: When a user clicks on '{clicked_label}' in an image, what are their most likely intentions?
        
        Step 1: Analyze user intentions
        Consider what a real person would want to do when they see and click on this object:
        - What questions might they have?
        - What actions would they naturally want to take?
        - What information would be useful to them?
        - What creative possibilities interest them?
        
        Step 2: Generate actions based on intentions
        For each identified user intention, provide the most appropriate action type and functionality.
        
        Action types available:
        1. **Image Edit** (action_type: "edit"): When user wants to modify the image
           - Change appearance (color, style, effects)
           - Remove or replace the object
           - Add elements or transform
           
        2. **Information** (action_type: "info"): When user wants to learn more
           - Get details, specifications, history
           - Understand usage or context
           
        3. **Navigate** (action_type: "navigate"): When user wants to visit related resources
           - Official websites, stores, services
           - Purchase or booking pages
           
        4. **Search** (action_type: "search"): When user wants to find related content
           - Similar items, reviews, tutorials
           - **For products**: Search on eBay or shopping platforms (use "site:ebay.com {clicked_label}" format)
        
        Step 3: Return 4-6 actions
        Return JSON list with actions that match real user intentions:
        [
            {{
                "id": 1,
                "label": "Short Button Text (user-friendly)",
                "emoji": "Icon",
                "description": "Clear description of what this action does",
                "color": "Hex Code (Green for Nav, Blue for Use, Orange for Edit, Purple for Info)",
                "probability": 0.8,
                "action_type": "edit|info|navigate|search",
                "editor_prompt": "Prompt for image generation AI (only if action_type='edit')",
                "action_data": {{
                    "url": "https://...",  // for navigate/search
                    "search_query": "...",  // for search (use "site:ebay.com {clicked_label}" for eBay)
                    "info_text": "...",  // for info
                    "search_engine": "ebay"  // optional: "ebay" for eBay searches
                }}
            }}
        ]
        
        Guidelines:
        - **User-first thinking**: Start with "What would a user want?" not "What features can I show?"
        - **Natural intentions**: Common user intentions include:
          * "I want to change how this looks" â†’ edit action
          * "I want to know more about this" â†’ info action
          * "I want to buy/find this" â†’ search/navigate action (for products, naturally include eBay)
          * "I want to remove this" â†’ edit action
          * "I want to see similar items" â†’ search action
        - **Product context**: If '{clicked_label}' is a product (clothing, shoes, bags, accessories), 
          users naturally want to: find where to buy it, see prices, compare options â†’ provide eBay search naturally
        - **Creative possibilities**: Users also enjoy creative exploration â†’ include 1-2 creative editing options
        - **Balance**: Mix practical and creative intentions based on what real users would want
        - **Web context**: If search results are provided, use them to inform realistic user intentions
        """
        
        try:
            if USE_NEW_SDK:
                response = client.models.generate_content(
                    model=self.model_name,
                    contents=[prompt, image],
                    config=types.GenerateContentConfig(
                        temperature=0.7,  # ç¨å¾®æé«˜æ¸©åº¦ä»¥åˆ©ç”¨ç½‘ç»œæœç´¢ç»“æœ
                        thinking_config=types.ThinkingConfig(thinking_budget=0)
                    )
                )
            else:
                response = self.model.generate_content([prompt, image]) 
            
            json_str = clean_json_string(response.text)
            data = json.loads(json_str)
            
            intents = []
            for item in data:
                # å¦‚æœ AI æ²¡æœ‰ç”Ÿæˆ action_typeï¼Œæ ¹æ® editor_prompt æ¨æ–­
                if "action_type" not in item:
                    item["action_type"] = "edit" if item.get("editor_prompt") else "info"
                
                # å¦‚æœ action_type æ˜¯ navigate/search ä½†æ²¡æœ‰ action_dataï¼Œå°è¯•ä» web_results å¡«å……
                if item["action_type"] in ["navigate", "search"] and not item.get("action_data"):
                    if web_results:
                        # å¯¹äºå•†å“ï¼Œå¦‚æœæ˜¯æœç´¢ç±»å‹ï¼Œä¼˜å…ˆä½¿ç”¨ eBay æœç´¢æ ¼å¼
                        if is_product and item["action_type"] == "search":
                            item["action_data"] = {
                                "search_query": f"{clicked_label} site:ebay.com",
                                "search_engine": "ebay",
                                "title": f"Search {clicked_label} on eBay"
                            }
                        else:
                            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæœç´¢ç»“æœä½œä¸ºé»˜è®¤é“¾æ¥
                            item["action_data"] = {
                                "url": web_results[0].get("link", ""),
                                "title": web_results[0].get("title", ""),
                                "search_query": f"{clicked_label} {item['label']}"
                            }
                
                # å¦‚æœ action_type æ˜¯ info ä½†æ²¡æœ‰ action_dataï¼Œä» web_results å¡«å……ä¿¡æ¯
                if item["action_type"] == "info" and not item.get("action_data"):
                    if web_results:
                        item["action_data"] = {
                            "info_text": web_results[0].get("snippet", ""),
                            "source_url": web_results[0].get("link", "")
                        }
                
                intents.append(RippleIntent(**item))
            return intents
        except Exception as e:
            print(f"Inference Error: {e}")
            return []

    async def execute_edit(self, image, prompt: str, box_2d: List[int], enable_image_edit: bool = True):
        """
        Step 3: æ‰§è¡Œå›¾åƒç¼–è¾‘ (Gemini Image Editing)
        ä½¿ç”¨ Gemini API è¿›è¡Œå›¾åƒç¼–è¾‘ï¼Œè¿”å›å¤„ç†åçš„å›¾ç‰‡ã€‚
        
        Args:
            image: PIL Image å¯¹è±¡
            prompt: ç¼–è¾‘æç¤ºè¯
            box_2d: ç›®æ ‡åŒºåŸŸ [y0, x0, y1, x1]
            enable_image_edit: æ˜¯å¦å¯ç”¨çœŸå®çš„å›¾åƒç¼–è¾‘ï¼ˆFalse æ—¶è¿”å›åŸå›¾ï¼‰
        """
        print(f"âš¡ï¸ Calling Gemini Image Edit with prompt: {prompt}")
        print(f"ğŸ“ Target Region: {box_2d}")
        print(f"ğŸ”„ Image Edit Enabled: {enable_image_edit}")
        
        if not enable_image_edit:
            # å¦‚æœç¦ç”¨å›¾åƒç¼–è¾‘ï¼Œè¿”å›åŸå›¾ï¼ˆç”¨äºæµ‹è¯•æˆ–æ¼”ç¤ºï¼‰
            print("âš ï¸ Image editing is disabled, returning original image")
            return image
        
        try:
            # æ„å»ºç¼–è¾‘æç¤ºè¯ï¼ŒåŒ…å«åŒºåŸŸä¿¡æ¯
            width, height = image.size
            y0, x0, y1, x1 = box_2d
            
            # å°†åæ ‡è½¬æ¢ä¸ºç›¸å¯¹ä½ç½®ï¼ˆ0-1ï¼‰
            x0_norm = x0 / width
            y0_norm = y0 / height
            x1_norm = x1 / width
            y1_norm = y1 / height
            
            # æ„å»ºåŒ…å«åŒºåŸŸä¿¡æ¯çš„å®Œæ•´æç¤ºè¯
            full_prompt = f"""Using the provided image, edit only the region at coordinates ({x0_norm:.2f}, {y0_norm:.2f}) to ({x1_norm:.2f}, {y1_norm:.2f}). 
            
{prompt}

Keep the rest of the image unchanged. Return the edited image."""
            
            # è°ƒç”¨ Gemini å›¾åƒç¼–è¾‘ API
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œä½¿ç”¨ gemini-2.5-flash-image æ¨¡å‹è¿›è¡Œå›¾åƒç¼–è¾‘
            # å®˜æ–¹ç¤ºä¾‹ä½¿ç”¨ [text_input, image_input] æˆ– [image_input, text_input]
            # ä½¿ç”¨ response_modalities=['Image'] ç¡®ä¿åªè¿”å›å›¾ç‰‡ï¼Œä¸è¿”å›æ–‡æœ¬
            if USE_NEW_SDK:
                response = client.models.generate_content(
                    model=self.image_edit_model_name,
                    contents=[full_prompt, image],  # æŒ‰ç…§å®˜æ–¹ç¤ºä¾‹ï¼šæ–‡æœ¬åœ¨å‰ï¼Œå›¾ç‰‡åœ¨å
                    config=types.GenerateContentConfig(
                        response_modalities=['Image'],  # åªè¿”å›å›¾ç‰‡ï¼Œä¸è¿”å›æ–‡æœ¬
                        # image_config=types.ImageConfig(
                        #     aspect_ratio="16:9",  # å¯é€‰ï¼šæ§åˆ¶è¾“å‡ºå›¾ç‰‡çš„æ˜¾ç¤ºæ¯”ä¾‹
                        # ),
                    )
                )
            else:
                # æ—§ SDK ä¹Ÿå°è¯•ä½¿ç”¨ç›¸åŒçš„é¡ºåº
                response = self.image_edit_model.generate_content([full_prompt, image])
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
            if not response:
                print("âš ï¸ Empty response from API")
                return image
            
            # æ£€æŸ¥ candidatesï¼ˆå“åº”å¯èƒ½è¢«å®‰å…¨ç­–ç•¥é˜»æ­¢ï¼‰
            if hasattr(response, 'candidates'):
                if not response.candidates or len(response.candidates) == 0:
                    print("âš ï¸ No candidates in response (may be blocked by safety settings)")
                    # æ£€æŸ¥æ˜¯å¦æœ‰é˜»æ­¢åŸå› 
                    if hasattr(response, 'prompt_feedback'):
                        print(f"ğŸ“‹ Prompt feedback: {response.prompt_feedback}")
                    return image
            
            # ä»å“åº”ä¸­æå–å›¾ç‰‡ï¼ˆæŒ‰ç…§å®˜æ–¹æ–‡æ¡£çš„æ–¹å¼ï¼‰
            try:
                # å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹ï¼šéå† response.parts
                if hasattr(response, 'parts'):
                    for part in response.parts:
                        # æ–¹æ³•1: æ£€æŸ¥æ–‡æœ¬å“åº”
                        if hasattr(part, 'text') and part.text is not None:
                            print(f"ğŸ“ Response text: {part.text}")
                        
                        # æ–¹æ³•2: æ£€æŸ¥ inline_data å¹¶ä½¿ç”¨ as_image()ï¼ˆå®˜æ–¹æ¨èæ–¹å¼ï¼‰
                        # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼šhttps://ai.google.dev/gemini-api/docs/image-generation
                        # part.as_image() è¿”å›çš„å¯¹è±¡å¯ä»¥ç›´æ¥è°ƒç”¨ save() æ–¹æ³•
                        elif hasattr(part, 'inline_data') and part.inline_data is not None:
                            # å…ˆæ‰“å° inline_data çš„ç»“æ„ç”¨äºè°ƒè¯•
                            print(f"ğŸ“‹ inline_data type: {type(part.inline_data)}")
                            print(f"ğŸ“‹ inline_data attributes: {[attr for attr in dir(part.inline_data) if not attr.startswith('_')]}")
                            
                            try:
                                # æ–¹æ³•1: å°è¯•ç›´æ¥ä½¿ç”¨ as_image()ï¼ˆå®˜æ–¹æ¨èï¼‰
                                edited_image = part.as_image()
                                print(f"ğŸ“‹ as_image() returned type: {type(edited_image)}")
                                if edited_image:
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯ PIL Image
                                    if isinstance(edited_image, Image.Image):
                                        if edited_image.mode != 'RGB':
                                            edited_image = edited_image.convert('RGB')
                                        print("âœ… Image editing successful (from part.as_image() - PIL Image)")
                                        return edited_image
                                    else:
                                        print(f"âš ï¸ as_image() returned non-PIL type: {type(edited_image)}")
                                        # å¦‚æœä¸æ˜¯ PIL Imageï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                                        raise ValueError(f"as_image() returned non-PIL type: {type(edited_image)}")
                            except Exception as e:
                                print(f"âš ï¸ Error using as_image(): {e}")
                                
                            # æ–¹æ³•2: å°è¯•ä» inline_data æ‰‹åŠ¨è§£ç 
                            try:
                                # æ£€æŸ¥ä¸åŒçš„æ•°æ®è®¿é—®æ–¹å¼
                                image_data = None
                                
                                # æ–¹å¼1: ç›´æ¥è®¿é—® data å±æ€§
                                if hasattr(part.inline_data, 'data'):
                                    data_attr = part.inline_data.data
                                    print(f"ğŸ“‹ inline_data.data type: {type(data_attr)}")
                                    if isinstance(data_attr, str):
                                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯• base64 è§£ç 
                                        image_data = base64.b64decode(data_attr)
                                    elif isinstance(data_attr, bytes):
                                        # å¦‚æœå·²ç»æ˜¯ bytesï¼Œç›´æ¥ä½¿ç”¨
                                        image_data = data_attr
                                    else:
                                        # å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†è§£ç 
                                        data_str = str(data_attr)
                                        if data_str.startswith('data:'):
                                            # å¤„ç† data URI æ ¼å¼
                                            data_str = data_str.split('base64,')[1] if 'base64,' in data_str else data_str
                                        image_data = base64.b64decode(data_str)
                                
                                # æ–¹å¼2: å°è¯•è®¿é—® bytes å±æ€§
                                elif hasattr(part.inline_data, 'bytes'):
                                    image_data = part.inline_data.bytes
                                
                                # æ–¹å¼3: å°è¯•è®¿é—® raw_data å±æ€§
                                elif hasattr(part.inline_data, 'raw_data'):
                                    raw = part.inline_data.raw_data
                                    if isinstance(raw, bytes):
                                        image_data = raw
                                    elif isinstance(raw, str):
                                        image_data = base64.b64decode(raw)
                                
                                if image_data:
                                    # å°è¯•æ‰“å¼€å›¾ç‰‡
                                    edited_image = Image.open(BytesIO(image_data))
                                    if edited_image.mode != 'RGB':
                                        edited_image = edited_image.convert('RGB')
                                    print("âœ… Image editing successful (from inline_data manual decode)")
                                    return edited_image
                                else:
                                    raise ValueError("Could not extract image data from inline_data")
                                    
                            except Exception as e2:
                                print(f"âš ï¸ Error in manual decoding: {e2}")
                                import traceback as tb
                                tb.print_exc()
                
                # æ–° SDK å¯èƒ½è¿˜æœ‰å…¶ä»–æ–¹å¼è®¿é—®å›¾ç‰‡
                # æ³¨æ„ï¼šæ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œåº”è¯¥ä½¿ç”¨ response.partsï¼Œè€Œä¸æ˜¯ response.images
                # æ‰€ä»¥è¿™é‡Œæš‚æ—¶æ³¨é‡Šæ‰ï¼Œä¼˜å…ˆä½¿ç”¨ä¸Šé¢çš„ parts éå†æ–¹å¼
                # if USE_NEW_SDK:
                #     if hasattr(response, 'images') and response.images:
                #         edited_image = response.images[0]
                #         print("âœ… Image editing successful (from response.images)")
                #         return edited_image
                
                # æ—§ SDK çš„ candidates æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            if hasattr(part, 'inline_data') and part.inline_data:
                                try:
                                    # ä¼˜å…ˆæ‰‹åŠ¨è§£ç  base64
                                    image_data = base64.b64decode(part.inline_data.data)
                                    edited_image = Image.open(BytesIO(image_data))
                                    if edited_image.mode != 'RGB':
                                        edited_image = edited_image.convert('RGB')
                                    print("âœ… Image editing successful (from candidate inline_data)")
                                    return edited_image
                                except Exception as e:
                                    print(f"âš ï¸ Error decoding candidate inline_data: {e}")
                                    # å›é€€åˆ° as_image()
                                    try:
                                        edited_image = part.as_image()
                                        if edited_image:
                                            # å¦‚æœæ˜¯ google.genai.types.Imageï¼Œéœ€è¦è½¬æ¢
                                            if not isinstance(edited_image, Image.Image):
                                                # å°è¯•ä» inline_data è·å–æ•°æ®
                                                if hasattr(part, 'inline_data') and part.inline_data:
                                                    image_data = base64.b64decode(part.inline_data.data)
                                                    edited_image = Image.open(BytesIO(image_data))
                                            if edited_image.mode != 'RGB':
                                                edited_image = edited_image.convert('RGB')
                                            print("âœ… Image editing successful (from candidate.parts.as_image())")
                                            return edited_image
                                    except Exception as e2:
                                        print(f"âš ï¸ Error using candidate as_image(): {e2}")
                    
            except Exception as e:
                print(f"âš ï¸ Error parsing response: {e}")
                import traceback
                traceback.print_exc()
            
            # å¦‚æœæ²¡æœ‰è¿”å›å›¾ç‰‡ï¼Œè¿”å›åŸå›¾
            print("âš ï¸ No image data in response, returning original image")
            print(f"ğŸ“‹ Response type: {type(response)}")
            if hasattr(response, 'text'):
                print(f"ğŸ“‹ Response text (first 200 chars): {response.text[:200]}")
            if hasattr(response, 'parts'):
                print(f"ğŸ“‹ Response has {len(response.parts)} parts")
                for i, part in enumerate(response.parts):
                    print(f"ğŸ“‹ Part {i} attributes: {[attr for attr in dir(part) if not attr.startswith('_')]}")
            return image
            
        except Exception as e:
            print(f"âŒ Image editing error: {e}")
            # å‡ºé”™æ—¶è¿”å›åŸå›¾
            return image

